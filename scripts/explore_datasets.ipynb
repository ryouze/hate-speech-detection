{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: explore_datasets.ipynb\n",
    "\n",
    "This notebook is a simple exploration of the dataset. It is a good starting point to understand the data structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from lib import filepaths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First version of the dataset (BAN-PL_1.zip)\n",
    "# - Upload Date: 16.08.2023\n",
    "# - Rows: 24,000\n",
    "# - Classes: 0 – non-harmful, 1 – harmful\n",
    "df1: pandas.DataFrame = pandas.read_csv(filepaths.datasets / \"BAN-PL_1.csv\")\n",
    "\n",
    "# Second version of the dataset (BAN-PL_2.zip)\n",
    "# - Upload Date: 05.04.2023\n",
    "# - Rows: 24,000\n",
    "# - Classes: 0 – non-harmful, 1 – harmful\n",
    "# - Moderation reasons: 4 pseudonymized classes representing moderation reasons\n",
    "df2: pandas.DataFrame = pandas.read_csv(filepaths.datasets / \"BAN-PL_2.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data\n",
    "\n",
    "Columns, rows, data types, missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_min_max(\n",
    "    df: pandas.DataFrame,\n",
    ") -> dict[str, tuple[float, float]]:\n",
    "    \"\"\"\n",
    "    Get min and max values for each numerical column in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame to get min and max values from.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, tuple[float, float]]: Dictionary with column names as keys and tuples with min and max values as values.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        column: (df[column].min(), df[column].max())\n",
    "        for column in df.select_dtypes(include=[numpy.number]).columns\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Number of rows:\n",
      "  df1 = 24,000\n",
      "  df2 = 24,000\n",
      "\n",
      "\n",
      "(2) Number of columns:\n",
      "  df1 = 3\n",
      "  df2 = 5\n",
      "\n",
      "\n",
      "(3) Column names:\n",
      "  df1 = ['id', 'Text', 'Class']\n",
      "  df2 = ['Unnamed: 0', 'id', 'Text', 'Class', 'Reason']\n",
      "\n",
      "\n",
      "(4) Column range (min, max):\n",
      "  df1 = {'Class': (0, 1)}\n",
      "  df2 = {'Unnamed: 0': (0, 23999), 'id': (0, 13499), 'Class': (0, 1), 'Reason': (1, 4)}\n",
      "\n",
      "\n",
      "(5) Column types:\n",
      "  df1 = {'id': dtype('O'), 'Text': dtype('O'), 'Class': dtype('int64')}\n",
      "  df2 = {'Unnamed: 0': dtype('int64'), 'id': dtype('int64'), 'Text': dtype('O'), 'Class': dtype('int64'), 'Reason': dtype('int64')}\n",
      "\n",
      "\n",
      "(6) Number of unique values in each column:\n",
      "  df1 = {'id': 13248, 'Text': 23985, 'Class': 2}\n",
      "  df2 = {'Unnamed: 0': 24000, 'id': 13397, 'Text': 23985, 'Class': 2, 'Reason': 4}\n",
      "\n",
      "\n",
      "(7) Number of NA values in each column:\n",
      "  df1 = {'id': 1, 'Text': 0, 'Class': 0}\n",
      "  df2 = {'Unnamed: 0': 0, 'id': 0, 'Text': 0, 'Class': 0, 'Reason': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"(1) Number of rows:\\n  df1 = {len(df1):,}\\n  df2 = {len(df2):,}\",\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\n\\n(2) Number of columns:\\n  df1 = {len(df1.columns):,}\\n  df2 = {len(df2.columns):,}\",\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\n\\n(3) Column names:\\n  df1 = {df1.columns.tolist()}\\n  df2 = {df2.columns.tolist()}\",\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"\\n\\n(4) Column range (min, max):\\n  df1 = {get_column_min_max(df1)}\\n  df2 = {get_column_min_max(df2)}\",\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"\\n\\n(5) Column types:\\n  df1 = {df1.dtypes.to_dict()}\\n  df2 = {df2.dtypes.to_dict()}\",\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\n\\n(6) Number of unique values in each column:\\n  df1 = {df1.nunique().to_dict()}\\n  df2 = {df2.nunique().to_dict()}\",\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\n\\n(7) Number of NA values in each column:\\n  df1 = {df1.isna().sum().to_dict()}\\n  df2 = {df2.isna().sum().to_dict()}\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First rows, random rows, last rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) First row:\n",
      "  df1 = [{'id': '2200', 'Text': '\\n\\n\\n            Polska wtedy oficjalnie powinna przyznać, że oddadzą (oczywiście zgodnie z prawem po wyrokach sądów polskich prawowitym spadkobiercom) jak tylko Niemcy oddadzą za zniszczenia jakich dokonali w II WŚ na terenie Polski (⌐ ͡■ ͜ʖ ͡■)                \\t\\t\\t\\n\\n\\n', 'Class': 0}]\n",
      "  df2 = [{'Unnamed: 0': 0, 'id': 2200, 'Text': '\\n\\n\\n            Polska wtedy oficjalnie powinna przyznać, że oddadzą (oczywiście zgodnie z prawem po wyrokach sądów polskich prawowitym spadkobiercom) jak tylko Niemcy oddadzą za zniszczenia jakich dokonali w II WŚ na terenie Polski (⌐ ͡■ ͜ʖ ͡■)                \\t\\t\\t\\n\\n\\n', 'Class': 0, 'Reason': 1}]\n",
      "\n",
      "\n",
      "(2) Last row:\n",
      "  df1 = [{'id': '12691', 'Text': 'Przecież murzynów nie da się szanować ani tolerować. Zawsze to samo. Jeden asfalt zostanie odstrzelony - reszta małp rozpie**** miasto. Gdzie tu logika?', 'Class': 1}]\n",
      "  df2 = [{'Unnamed: 0': 23999, 'id': 12691, 'Text': 'Przecież murzynów nie da się szanować ani tolerować. Zawsze to samo. Jeden asfalt zostanie odstrzelony - reszta małp rozpie**** miasto. Gdzie tu logika?', 'Class': 1, 'Reason': 3}]\n",
      "\n",
      "\n",
      "(3) Random row:\n",
      "  df1 = [{'id': '137', 'Text': '{USERNAME}: Mitoman pierdolony', 'Class': 1}]\n",
      "  df2 = [{'Unnamed: 0': 20217, 'id': 4140, 'Text': '{USERNAME} nie jest. Trzeba zabić ruskich.', 'Class': 1, 'Reason': 3}]\n",
      "\n",
      "\n",
      "(4) Random 10 rows (text only):\n",
      "  df1 = ['{USERNAME}: nie, to nie jest warunek bezpieczeństwa płatności kartą. Nie wiem skąd wy się bierzecie xdd', '{USERNAME}: ale wam się pod dupami pali co?xD', 'samochód też prawie 5m\\n \\n {USERNAME}: Ej, ale od dużych samochodów to się proszę odtentegować. Fajne są.', '{USERNAME}: edytujesz komentarze tak szybko jak dupa nowelizuje ustawy zaraz po podpisaniu', '{USERNAME}: no i przecież ma rację? Żymianie do gazu', '{USERNAME}: Ty jesteś mistrzem zużycia zasobów. Twoją biomasę powinno się przerobić na paszę dla świń, to byłby jakiś pożytek...', '\\n\\n            {USERNAME}: Nie. Obiecał zrobić park to zrobi park. Nic nie obiecał w kwestii zalesienia na terenie parku                \\t\\t\\t', '\\n  czarna zaraza mówi o tęczowej zarazie xD \\n\\n{USERNAME}: \\n\\nPrzecież to jest jedna i ta sama zaraza: LGBTKK+                \\t\\t\\t', '{USERNAME}: Katokonserwowe , przegrywowe urojenia.', '{USERNAME}: Jebany debil XD']\n",
      "  df2 = ['{USERNAME}: Tyle że myślami nie da się symulować, wiec twierdzenie jest nieprawdziwe ( ͡~ ͜ʖ ͡°)', 'Widzę, że bydło znowu się rozbiegło po mikroblogu, przydałby się kolejny banhammer żeby przypomnieć im gdzie jest ich miejsce na tym portalu.\\n#neuropa #bekazprawakow', 'Oczywiście [pseudonym] z downem usunęła post \"Nienawiść lub przemoc\" niby co jest tu niewłaściwego? Nienawiścią jest że człowiek zachęca do zgłaszania na policję gwałtów?\\n\\nDlaczego w Polsce dorosłe kobiety nie zgłaszają wszystkich gwałtów na policji.\\nZazwyczaj w telewizji lub internecie widzimy zakazane patologiczne ryje poszukiwane/skazane za gwałt na kobiecie ale statystyki policyjne mówią że większość gwałtów nie jest zgłaszana...\\nDlaczego? Powód jest jeden-gwałcą nie tylko brzydale czy ludzie z marginesu społecznego ale i \"Chady\", niestety ich gwałty nie są zgłaszane służbom.\\nSerial dla nastolatek \"13 powodów\" doskonale obrazuje jak dzisiejsze kobiety podchodzą do faktu zgwałcenia przez przystojnego mężczyznę. Bohaterka serialu widząc wykorzystanie seksualne koleżanki nie powiadamia nikogo o tym fakcie a gdy sama zostaje zgwałcona woli popełnić samobójstwo niż dokonać zemsty.\\nZapewne małpi rozum płci żeńskiej usprawiedliwia to przestępstwo przez to że człowiek dokonujący tego był \"przystojny\"\\nNormiki napiszą \"to tylko serial nie znasz się kurwa hahah\" ale statystyki mówią swoje.\\n\\nMówimy tu tylko o prawdziwych przestępstwach a nie o kłamstwach kobiet i fałszywych oskarżeniach które zdarzają się o wiele częściej\\n\\nWołam plusujących na złość [pseudonym] {USERNAME} {USERNAME} {USERNAME} {USERNAME} {USERNAME} {USERNAME} {USERNAME} {USERNAME} {USERNAME} {USERNAME} \\n\\n#pasta #p0lka #logikarozowychpaskow #przegryw', '{USERNAME}: Jak na razie to jedynym debilem jesteś ty.', '{USERNAME}: Takich ludzików co grożą śmiercią powinno się utylizować.', '> że kucykowi krzywda się nie dzieje.\\n\\n{USERNAME}: Może ktoś ci tak przypierdoli, krzywdy nie będzie', '{URL} {URL}\\n{URL} {USERNAME} #rozowypasek #logikarozowychpaskow', '{USERNAME}: \\n > amerykanin zużywa średnio 4- 5 razy więcej energii niż Europejczyk\\n 2 razy więcej', 'Bardzo dobrze jebac spekulantów i rentierow', '\\n\\n            {USERNAME}: zakładasz  że człowiek nie jest częścią natury ( ͡° ͜ʖ ͡°)                \\t\\t\\t']\n",
      "\n",
      "\n",
      "(5) Top 25 most common words:\n",
      "  df1 = {'to': 16118, 'nie': 15856, 'i': 15678, '{USERNAME}:': 14877, 'w': 14509, 'na': 12562, 'z': 10154, 'się': 9866, 'że': 7802, 'do': 6545, 'jest': 6368, 'jak': 6269, 'a': 5278, 'co': 4236, 'za': 3793, 'o': 3655, 'bo': 3608, 'ale': 3437, 'tak': 3001, 'po': 2970, '{USERNAME}': 2586, 'ma': 2529, '-': 2434, 'od': 2432, 'ze': 2390}\n",
      "  df2 = {'to': 16118, 'nie': 15856, 'i': 15678, '{USERNAME}:': 14877, 'w': 14509, 'na': 12562, 'z': 10154, 'się': 9866, 'że': 7802, 'do': 6545, 'jest': 6368, 'jak': 6269, 'a': 5278, 'co': 4236, 'za': 3793, 'o': 3655, 'bo': 3608, 'ale': 3437, 'tak': 3001, 'po': 2970, '{USERNAME}': 2586, 'ma': 2529, '-': 2434, 'od': 2432, 'ze': 2390}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"(1) First row:\\n  df1 = {df1.head(1).to_dict(orient='records')}\\n  df2 = {df2.head(1).to_dict(orient='records')}\",\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"\\n\\n(2) Last row:\\n  df1 = {df1.tail(1).to_dict(orient='records')}\\n  df2 = {df2.tail(1).to_dict(orient='records')}\",\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\n\\n(3) Random row:\\n  df1 = {df1.sample(1).to_dict(orient='records')}\\n  df2 = {df2.sample(1).to_dict(orient='records')}\",\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\n\\n(4) Random 10 rows (text only):\\n  df1 = {[row['Text'] for row in df1.sample(10).to_dict(orient='records')]}\\n  df2 = {[row['Text'] for row in df2.sample(10).to_dict(orient='records')]}\",\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\n\\n(5) Top 25 most common words:\\n  df1 = {df1['Text'].str.split(expand=True).stack().value_counts().head(25).to_dict()}\\n  df2 = {df2['Text'].str.split(expand=True).stack().value_counts().head(25).to_dict()}\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hate-speech-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
